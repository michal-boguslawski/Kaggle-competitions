{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d18d92cb",
   "metadata": {},
   "source": [
    "A shout out to H-Z-Ning and his notebook\n",
    "<a href=\"https://www.kaggle.com/code/hzning/top-10-solution-0-97525-esay-is-all-you#%F0%9F%8F%81-LightGBM-Training\">🔥 Top 10% Solution|🏆0.97525,esay is all you!🚀</a>\n",
    "for feature engineering ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d7896",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50595b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import TargetEncoder, FunctionTransformer, Binarizer, OrdinalEncoder\n",
    "import imblearn.pipeline as imb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn import set_config\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "path = Path.cwd().parent\n",
    "\n",
    "# Absolute path to your package\n",
    "sys.path.append(os.path.join(path))\n",
    "\n",
    "from utils import convert_months_to_categorical, calculate_score, ClipValues, SinePreprocess, CategoryCounter\n",
    "\n",
    "# Enable pandas output globally\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5fb3f",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180e6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_file_path = os.path.join(path, \"raw\", \"train.csv\")\n",
    "test_file_path = os.path.join(path, \"raw\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1e07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_df = pd.read_csv(train_file_path, index_col=0)\n",
    "test_df = pd.read_csv(test_file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7c89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var = \"y\"\n",
    "categorical_variables = original_train_df.select_dtypes(include=\"object\").columns.to_list()\n",
    "numerical_variables = (\n",
    "    original_train_df\n",
    "    .select_dtypes(exclude=\"object\")\n",
    "    .columns\n",
    "    .drop(\n",
    "        labels=[\"y\"]\n",
    "    )\n",
    "    .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5c211",
   "metadata": {},
   "source": [
    "## Train val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b775c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(original_train_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b1e82",
   "metadata": {},
   "source": [
    "## Preprocessing and train Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b0d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad0fe268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_category(df):\n",
    "    # cat_cols = [\"default\", \"housing\", \"loan\", \"poutcome\", \"education\", \"contact\", \"job\", \"marital\"]\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "    return df\n",
    "\n",
    "def add_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"balance_negative_times_default_yes\"] = (df[\"balance\"] < 0) * (df['default'] == \"yes\")\n",
    "    df[\"balance_negative_times_loan_yes\"] = (df[\"balance\"] < 0) * (df['loan'] == \"yes\")\n",
    "    df[\"balance_negative\"] = (df[\"balance\"] < 0).astype(int)\n",
    "    df[\"balance_log\"] = np.log1p(df['balance'].clip(lower=0))\n",
    "    df[\"default_yes_times_loan_yes\"] = (df['default'] == \"yes\") * (df['loan'] == \"yes\")\n",
    "    df[\"contact_unknown_times_default_yes\"] = (df['contact'] == \"unknown\") * (df['default'] == \"yes\")\n",
    "    df[\"duration_times_loan_yes\"] = (df[\"duration\"]) * (df['loan'] == \"yes\")\n",
    "    df[\"duration_times_housing_yes\"] = (df[\"duration\"]) * (df['housing'] == \"yes\")\n",
    "    df[\"duration_times_contact_unknown\"] = (df[\"duration\"]) * (df['contact'] == \"unknown\")\n",
    "    df[\"duration_times_age\"] = (df[\"duration\"] < 53) * (df[\"age\"])\n",
    "    df[\"balance_negative_times_poutcome_unknown\"] = (df[\"balance\"] < 0) * (df['poutcome'] == \"unknown\")\n",
    "    df[\"duration_times_default_yes\"] = (df[\"duration\"]) * (df['default'] == \"yes\")\n",
    "    df[\"duration_times_education_primary\"] = (df[\"duration\"]) * (df['education'] == \"primary\")\n",
    "    df[\"pdays_by_campaign\"] = (df[\"pdays\"]) / (df['campaign'])\n",
    "    df[\"previous_by_campaign\"] = (df[\"previous\"]) / (df['campaign'] + 1e-8)\n",
    "    df[\"pdays_times_previous\"] = (df[\"pdays\"]) * (df['previous'])\n",
    "    df[\"day_of_year\"] = df[\"month\"].cat.codes * 30 + df[\"day\"]\n",
    "    df[\"duration_sq\"] = df[\"duration\"] ** 2\n",
    "    df['job_edu'] = df['job'].astype(str) + \"_\" + df['education'].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "power_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"passthrough\", \"passthrough\"),\n",
    "        # (\"clip\", ClipValues(quantile_range=(0.25, 0.75))),\n",
    "        # (\"power_transform\", PowerTransformer(\"yeo-johnson\", standardize=True)),\n",
    "        # (\"splines\", SplineTransformer(n_knots=10, knots=\"quantile\"))\n",
    "    ],\n",
    ")\n",
    "\n",
    "cat_encoder = Pipeline(\n",
    "    [\n",
    "        (\"encoder\", CategoryCounter()),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "target_encoder = TargetEncoder()\n",
    "sin_preprocess = SinePreprocess(\n",
    "    {\n",
    "        \"day\": 31,\n",
    "        \"month\": 12,\n",
    "        \"duration\": 400\n",
    "    }\n",
    ")\n",
    "\n",
    "preprocessing_pipeline_0 = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical\", power_pipeline, [\n",
    "            \"balance\", \"duration\", \"campaign\", \"pdays\", \"age\",\n",
    "        ]),\n",
    "        (\"binarizer\", Binarizer(threshold=0.01), [\"balance\", \"pdays\"]),\n",
    "        (\"encode\", \"passthrough\", [\"default\", \"housing\", \"loan\", \"poutcome\", \"education\", \"contact\", \"job\", \"marital\"]),\n",
    "        (\"target_encoder\", target_encoder, [\"day\", \"month\", \"default\", \"housing\", \"loan\", \"poutcome\", \"education\", \"contact\", \"job\", \"marital\", \"job_edu\"]),\n",
    "        (\"sine_preproces\", sin_preprocess, [\"day\", \"month\", \"duration\"]),\n",
    "        (\"drop\", \"drop\", [\"previous\"])\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    "    # verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "def create_pipeline(params = {}):\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"force_cats\", FunctionTransformer(force_category, validate=False)),\n",
    "            (\"month_transform_to_categorical\", FunctionTransformer(\n",
    "                convert_months_to_categorical, \n",
    "                validate=False,\n",
    "            )),\n",
    "            (\"add_columns\", FunctionTransformer(\n",
    "                add_columns, \n",
    "                validate=False,\n",
    "            )),\n",
    "            (\"preprocess_0\", preprocessing_pipeline_0),\n",
    "            (\"drop_not_needed\", \n",
    "            ColumnTransformer(transformers=[\n",
    "                (\"drop\", \"drop\", []),\n",
    "            ], remainder=\"passthrough\", verbose_feature_names_out=False)\n",
    "            ),\n",
    "            # (\"smote\", SMOTE(random_state=42)),\n",
    "            (\"classifier\", xgb.XGBClassifier(\n",
    "                tree_method=\"hist\", \n",
    "                enable_categorical=True,\n",
    "                objective=\"binary:logistic\",\n",
    "                eval_metric=\"logloss\",\n",
    "                **params\n",
    "            ))\n",
    "        ]\n",
    "    )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56fc303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = create_pipeline({\n",
    "    \"n_estimators\": 1000,\n",
    "    \"eta\": 0.03\n",
    "})\n",
    "fitted_pipeline = pipeline.fit(train_df.drop(\"y\", axis=1), train_df[y_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09c415e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': np.float64(0.9740406960275618),\n",
       " 'accuracy': 0.9429133333333334,\n",
       " 'f1': 0.7495026913175755}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df_preprocessed = fitted_pipeline.transform(train_df)\n",
    "train_pred_probs = fitted_pipeline.predict_proba(train_df)[:, 1]\n",
    "calculate_score(train_df[\"y\"], train_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781edb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': np.float64(0.9697476957775893),\n",
       " 'accuracy': 0.9393666666666667,\n",
       " 'f1': 0.7334954727928034}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df_preprocessed = fitted_pipeline.transform(train_df)\n",
    "val_pred_probs = fitted_pipeline.predict_proba(val_df)[:, 1]\n",
    "calculate_score(val_df[\"y\"], val_pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df918ff",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5fe8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3984e6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 09:40:46,832] A new study created in memory with name: Bank\n",
      "[I 2025-08-12 09:44:50,184] Trial 0 finished with value: 0.9597799331783436 and parameters: {'booster': 'dart', 'min_child_weight': 1.0566129870444458e-08, 'max_depth': 15, 'max_leaves': 3, 'eta': 0.5797875044895596, 'gamma': 0.0005432905030227457, 'lambda': 0.031583785543398225, 'alpha': 0.022350531407423064, 'subsample': 0.4143404618790661, 'colsample_bytree': 0.47847658174885305, 'scale_pos_weight': 2.7105424687944515, 'n_estimators': 87}. Best is trial 0 with value: 0.9597799331783436.\n",
      "[I 2025-08-12 09:45:01,172] Trial 1 finished with value: 0.9630581966284519 and parameters: {'booster': 'gbtree', 'min_child_weight': 0.001402656553561887, 'max_depth': 7, 'max_leaves': 5, 'eta': 0.49393401723438174, 'gamma': 0.00022502887935703242, 'lambda': 1.6857715338075006e-08, 'alpha': 9.156586010334946e-08, 'subsample': 0.571549593483784, 'colsample_bytree': 0.9677199349103318, 'scale_pos_weight': 9.123087450050388, 'n_estimators': 107}. Best is trial 1 with value: 0.9630581966284519.\n",
      "[I 2025-08-12 10:00:45,712] Trial 2 finished with value: 0.9635554023339035 and parameters: {'booster': 'dart', 'min_child_weight': 1.9069936234138043e-07, 'max_depth': 3, 'max_leaves': 65, 'eta': 0.3588388155561183, 'gamma': 8.754865381050208e-08, 'lambda': 1.700873974383086e-08, 'alpha': 6.071312777518333e-06, 'subsample': 0.4716158868182439, 'colsample_bytree': 0.20221107427402965, 'scale_pos_weight': 8.900097978625254, 'n_estimators': 170}. Best is trial 2 with value: 0.9635554023339035.\n",
      "[I 2025-08-12 10:00:57,737] Trial 3 finished with value: 0.9655440527336785 and parameters: {'booster': 'gbtree', 'min_child_weight': 0.000779248539485378, 'max_depth': 6, 'max_leaves': 61, 'eta': 0.17865251758532608, 'gamma': 5.016862585100711e-08, 'lambda': 0.0001964994322956821, 'alpha': 1.5624000567113944e-05, 'subsample': 0.5005231346539298, 'colsample_bytree': 0.6583507744337163, 'scale_pos_weight': 1.8565773232489682, 'n_estimators': 73}. Best is trial 3 with value: 0.9655440527336785.\n",
      "[W 2025-08-12 10:11:51,340] Trial 4 failed with parameters: {'booster': 'dart', 'min_child_weight': 2.6541290118584544, 'max_depth': 12, 'max_leaves': 10, 'eta': 0.08194706654030046, 'gamma': 0.009927998774249042, 'lambda': 1.0048991369234139e-06, 'alpha': 0.0011677935704194264, 'subsample': 0.5648738392928399, 'colsample_bytree': 0.5321407953789874, 'scale_pos_weight': 8.207706105864858, 'n_estimators': 144} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bogus\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\bogus\\AppData\\Local\\Temp\\ipykernel_12452\\2631205472.py\", line 19, in objective\n",
      "    fitted_pipeline = pipeline.fit(train_df.drop(\"y\", axis=1).copy(), train_df[y_var].copy())\n",
      "  File \"C:\\Users\\bogus\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\bogus\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\bogus\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\bogus\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\sklearn.py\", line 1682, in fit\n",
      "    self._Booster = train(\n",
      "                    ~~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<9 lines>...\n",
      "        callbacks=self.callbacks,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\bogus\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\bogus\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py\", line 183, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\bogus\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py\", line 2247, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self.handle, ctypes.c_int(iteration), dtrain.handle\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-12 10:11:51,351] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 3. Create a study object and optimize the objective function.\u001b[39;00m\n\u001b[32m     25\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m, study_name=\u001b[33m\"\u001b[39m\u001b[33mBank\u001b[39m\u001b[33m\"\u001b[39m, sampler=optuna.samplers.NSGAIISampler())\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     17\u001b[39m pipeline = create_pipeline(param)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# sample = train_df.sample(100000)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m fitted_pipeline = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_var\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m val_pred_probs = fitted_pipeline.predict_proba(val_df)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     21\u001b[39m scores = calculate_score(val_df[\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m], val_pred_probs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\pipeline.py:662\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    657\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    658\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    659\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    660\u001b[39m             all_params=params,\n\u001b[32m    661\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\sklearn.py:1682\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1660\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1661\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1662\u001b[39m )\n\u001b[32m   1663\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1664\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1665\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1679\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1680\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # 2. Suggest values of the hyperparameters using a trial object.\n",
    "    param = {\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-8, 10, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 50, log=True),\n",
    "        \"max_leaves\": trial.suggest_int(\"max_leaves\", 1, 250, log=True),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 1e-8, 1.0, log=False),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 10.0, log=True),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.1, 10.0),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200, log=True)\n",
    "    }\n",
    "    pipeline = create_pipeline(param)\n",
    "    # sample = train_df.sample(100000)\n",
    "    fitted_pipeline = pipeline.fit(train_df.drop(\"y\", axis=1).copy(), train_df[y_var].copy())\n",
    "    val_pred_probs = fitted_pipeline.predict_proba(val_df)[:, 1]\n",
    "    scores = calculate_score(val_df[\"y\"], val_pred_probs)\n",
    "    return scores[\"auc\"]\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize', study_name=\"Bank\", sampler=optuna.samplers.NSGAIISampler())\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263e5381",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80cc9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = study.best_trial.params\n",
    "pipeline = create_pipeline(param)\n",
    "fitted_pipeline = pipeline.fit(train_df.drop(\"y\", axis=1), train_df[y_var])\n",
    "# test = fitted_pipeline.transform(sample.drop(\"y\", axis=1))\n",
    "# fitted_pipeline = pipeline.fit(train_df.drop(\"y\", axis=1), train_df[y_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e4b91ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': np.float64(0.9664443952657242),\n",
       " 'accuracy': 0.8844966666666667,\n",
       " 'f1': 0.6627410139863543}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df_preprocessed = fitted_pipeline.transform(train_df)\n",
    "train_pred_probs = fitted_pipeline.predict_proba(train_df)[:, 1]\n",
    "calculate_score(train_df[\"y\"], train_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7469bd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': np.float64(0.9650362958919594),\n",
       " 'accuracy': 0.88396,\n",
       " 'f1': 0.6599593654762835}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df_preprocessed = fitted_pipeline.transform(train_df)\n",
    "val_pred_probs = fitted_pipeline.predict_proba(val_df)[:, 1]\n",
    "calculate_score(val_df[\"y\"], val_pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14abc09",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipeline[-1].get_booster().get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828d942",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = study.best_trial_params\n",
    "pipeline = create_pipeline(param)\n",
    "fitted_pipeline = pipeline.fit(original_train_df.drop(\"y\", axis=1), original_train_df[y_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_probs = fitted_pipeline.predict_proba(test_df)\n",
    "test_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_df[[]]\n",
    "submission = submission.copy()\n",
    "submission.loc[:, \"y\"] = test_pred_probs[:, 1]\n",
    "submission.to_csv(\"submission_xgb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
